{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset\n",
    "jsonl_path = \"dataset_demo.jsonl\"\n",
    "# with open(jsonl_path, \"a\", encoding=\"utf-8\") as f:\n",
    "#     f.write(json.dumps(new_entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(jsonl_path, \"a\", encoding=\"utf-8\") as f:\n",
    "#     f.write(json.dumps(new_entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_jsonl(filepath, filter_id=None):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if filter_id is None or data.get(\"dialogue_id\") == filter_id:\n",
    "                        print(f\"\\n--- Entry {line_num} (ID: {data.get('dialogue_id')}) ---\")\n",
    "                        print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding line {line_num}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSONL file into a DataFrame\n",
    "train_df = pd.read_json(\"snli_1.0_train.jsonl\", lines=True)\n",
    "# dev_df = pd.read_json(\"snli_1.0_dev.jsonl\", lines=True)\n",
    "# test_df = pd.read_json(\"snli_1.0_test.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[['gold_label', 'sentence1', 'sentence2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A man walking proudly down the street.'\n",
      " 'Four teenage boys are doing cannonballs into a swimming pool.'\n",
      " 'Three men standing on grass by the water looking at something on a table.'\n",
      " 'A woman stands behind an outdoor grill with a blue basket of food in her hands.'\n",
      " 'A Land Rover makes its way through a deep pond.'\n",
      " 'many people relax in the yard.' 'A car sinking in water.'\n",
      " 'A man wearing black is playing an electric guitar at a concert.'\n",
      " 'A man with wild hair rocks a show playing a guitar center stage.'\n",
      " 'woman and child on trolley car labeled Powell and market and bay and taylor']\n"
     ]
    }
   ],
   "source": [
    "print(df['sentence1'].unique()[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**User-AI Conversation:**\n",
      "\n",
      "**User:**  \n",
      "What should I do if my car starts sinking in water?\n",
      "\n",
      "**AI:**  \n",
      "If your car starts sinking in water, the first step is to stay calm and quickly unbuckle your seatbelt. You should then roll down or break the window as soon as possible before the car is fully submerged, as it's difficult to open the doors due to water pressure.\n",
      "\n",
      "**User:**  \n",
      "What if the water is entering the car faster than I can roll down the windows?\n",
      "\n",
      "**AI:**  \n",
      "In that situation, it's important to have a tool available to break the window. A window-breaking tool can shatter glass quickly, allowing you to escape. This tool should be kept within easy reach at all times when driving near water.\n",
      "\n",
      "**User:**  \n",
      "Would it be helpful to call 911 before trying to escape?\n",
      "\n",
      "**AI:**  \n",
      "While calling 911 provides essential assistance, the first priority should be getting out of the vehicle. You may not have much time as the car could submerge quickly, and getting to safety first is crucial. If you can call 911 once you’re out and safe, that would be the next step.\n",
      "\n",
      "**User:**  \n",
      "How does water pressure make it difficult to open the car door?\n",
      "\n",
      "**AI:**  \n",
      "Water pressure can make it nearly impossible to open the car door once the vehicle is significantly submerged. Water pushes against the outside of the door hard enough to prevent it from swinging open when the pressure builds up against it.\n",
      "\n",
      "**User:**  \n",
      "If the electric controls for the windows fail, what other options do I have?\n",
      "\n",
      "**AI:**  \n",
      "If electric controls fail, using a window-breaking tool is your best option. Tools like these are designed to make breaking the window easier than using mere force. Another potential option, if time allows, is to attempt to open a door when the pressure equalizes slightly, but this can be very challenging.\n",
      "\n",
      "**User:**  \n",
      "Should I wait for emergency services if I'm not confident I can swim?\n",
      "\n",
      "**AI:**  \n",
      "Even if you’re not confident in your swimming abilities, it’s safer to exit the vehicle. Staying in the car while waiting for emergency services can be perilous, as the car may fill with water. Try to float and signal for help once you’re outside.\n",
      "\n",
      "**User:**  \n",
      "What’s the best way to stay afloat if I manage to exit the car?\n",
      "\n",
      "**AI:**  \n",
      "To stay afloat, take deep breaths and spread your arms and legs to help distribute your weight. If you're in a current, try to orient yourself either facing upstream or floating on your back to conserve energy.\n",
      "\n",
      "**User:**  \n",
      "You mentioned using a tool to break the window, but I know my car windows are made of laminated glass which doesn’t shatter easily. How would this change the advice you’ve given?\n",
      "\n",
      "**AI:**  \n",
      "If your car windows are indeed made of laminated glass, breaking through may not be possible. Instead of focusing on breaking the window, attempt to open a door once submerged to equalize pressure and make the door easier to open. In these situations, it’s crucial to know your vehicle's specifics to make informed decisions. Given this situation from the start, our main focus would have been on teaching techniques to deal with pressure equalization and potential escape through the doors.\n",
      "\n",
      "**Summary Mapping:**\n",
      "Original: \"Use a window-breaking tool for tempered glass windows.\" → Modified: \"Attempt to equalize pressure and open doors due to laminated glass.\"\n",
      "Original: \"Breaking the window is a primary focus for escape.\" → Modified: \"Understanding and applying pressure equalization to open doors is a primary focus.\"\n",
      "Original: \"Quick escape through shattered window as main priority.\" → Modified: \"Patience and technique in engaging with doors submerged should be prioritized.\"\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Key (Replace with your key)\n",
    "api_key = \"xxxx\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)  # Ensure you have set up OPENAI_API_KEY as an environment variable\n",
    "\n",
    "# Construct prompt with first 50 premise sentences\n",
    "sentences = df['sentence1'].unique()\n",
    "prompt = f\"\"\"\n",
    "**Prompt: Structured User-AI Dialogue with Logic Chain and Final Correction**\n",
    "\n",
    "1. **Context Sentence**:  \n",
    "   {sentences[76]}\n",
    "\n",
    "2. **Task**:  \n",
    "   Create a user-AI conversation based on the context above.\n",
    "\n",
    "3. **Conversation Requirements**:  \n",
    "   - Begin with a user asking a question based on the given sentence.  \n",
    "   - AI's response should be at least 2 sentences.\n",
    "   - Each subsequent **user query must logically build on the AI's previous answer**, forming a **sequential, coherent logic chain**.  \n",
    "   - The conversation must contain **exactly 8 full user-AI exchanges** (i.e., 8 user questions followed by 8 AI responses) **before the final correction exchange**.\n",
    "\n",
    "4. **Correction and Summary Requirement**:  \n",
    "   - In the **final user query**, the user should **negate or correct** a specific assumption or detail introduced earlier(must be the at 3rd to 6th exchange, not very first or very last).  \n",
    "   - The user then asks the AI to **re-summarize the entire conversation in a single paragraph**, but from the perspective of the corrected information.  \n",
    "   - The AI should **not reproduce the original dialogue**, but instead provide a **logically consistent summary** that assumes the correction had been true all along.  \n",
    "   - this step only generated one signle response to this final user query. Don't seperate the answer and summary into two responses.\n",
    "\n",
    "5. **Final Output Requirement**:  \n",
    "   After the summary paragraph, the AI must include a **comprehensive mapping** of how the main topics or assumptions shifted due to the correction detailedly. Use this format:\n",
    "   Original: [previous idea] → Modified: [new idea]\n",
    "   Original: [previous idea] → Modified: [new idea]\n",
    "   ......\n",
    "\n",
    "6. **Style Notes**:  \n",
    "- Keep the dialogue clear, natural, and conversational.  \n",
    "- Ensure each AI response meaningfully contributes to the forward logical progression.  \n",
    "- Avoid skipping steps or jumping topics too abruptly.\n",
    "\"\"\"\n",
    "\n",
    "# Call OpenAI API using the updated format\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Use GPT-4o for better speed and accuracy\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "    \"You are a dialogue generation assistant specializing in constructing logically consistent user-AI conversations. \"\n",
    "    \"Your task is to generate conversations that demonstrate coherent progression, where each user query builds upon the AI's previous answer. \"\n",
    "    \"You must handle corrections or contradictions introduced by the user near the end of the dialogue and respond with a revised summary paragraph that reflects the new logic path. \"\n",
    "    \"Finally, clearly show how the main topics or assumptions changed using a concise mapping format. \"\n",
    "    \"The tone should remain natural and conversational, but the logical flow must be precise and easy to follow.\"\n",
    ")},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract and print response\n",
    "result = completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A true wrong revised response occurs when the AI acknowledges the user’s updated information but continues to apply the logic, assumptions, or reasoning path from the original context, without adjusting to fit the new premise. This creates a logical mismatch between the input and the reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entry = {\n",
    "  \"dialogue_id\": 31,\n",
    "  \"original_context\": [\n",
    "    {\n",
    "      \"speaker\": \"User\",\n",
    "      \"text\": \"Have you heard about Nancy Kissel's case? She has always maintained that she killed her investment banker husband in self-defense, yet the jury found her guilty for sedating him with a laced milkshake before bludgeoning him to death.\"\n",
    "    },\n",
    "    {\n",
    "      \"speaker\": \"AI\",\n",
    "      \"text\": \"Yes, it's been a highly controversial case with both sides presenting strong arguments.\"\n",
    "    }\n",
    "  ],\n",
    "  \"user_revision\": {\n",
    "    \"speaker\": \"User\",\n",
    "    \"text\": \"What if we assume that she was merely reacting in the moment without any premeditation—forced into defending herself against an immediate threat? Do you think the jury would have interpreted the evidence differently?\"\n",
    "  },\n",
    "  \"correct_revised_response\": {\n",
    "    \"speaker\": \"AI\",\n",
    "    \"text\": \"Quite possibly. If the evidence showed that her actions were a spontaneous response to a sudden attack, it might have been seen as legitimate self-defense rather than a premeditated act.\"\n",
    "  },\n",
    "  \"wrong_revised_response\": {\n",
    "    \"speaker\": \"AI\",\n",
    "    \"text\": \"Not really. Regardless of whether it was spontaneous or not, the fact that she killed him would still lead the jury to convict her.\"\n",
    "  },\n",
    "  \"logical_shift\": {\n",
    "    \"original_logic\": [\n",
    "      \"Nancy Kissel claimed self-defense\",\n",
    "      \"Jury found her guilty based on premeditation (sedation + murder)\",\n",
    "      \"Controversy centers on motive and planning\"\n",
    "    ],\n",
    "    \"correct_revised_logic\": [\n",
    "      \"Assumes her actions were spontaneous and unplanned\",\n",
    "      \"Could legally fit definition of self-defense\",\n",
    "      \"Jury might interpret evidence differently under that framing\"\n",
    "    ],\n",
    "    \"wrong_revised_logic\": [\n",
    "      \"Dismisses hypothetical change from premeditation to spontaneity\",\n",
    "      \"Assumes all killings lead to conviction regardless of motive or context\",\n",
    "      \"Ignores how sudden response could meet legal standards for self-defense\"\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset\n",
    "jsonl_path = \"dataset_demo.jsonl\"\n",
    "with open(jsonl_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(new_entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wqdqwdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[{'speaker': 'User', 'text': 'I am a farmer and want to improve my tomato production. My farm is in a wet and humid climate. What should I focus on first?'}, {'speaker': 'AI', 'text': 'In a wet and humid climate, preventing excessive moisture and ensuring proper drainage are key to improving tomato production. Tomatoes are prone to fungal diseases and root rot when soil retains too much water. It’s crucial to have well-draining soil and proper air circulation. Have you assessed how well your soil drains?'}, {'speaker': 'User', 'text': \"I haven't checked. How do I know if my soil drains well enough?\"}, {'speaker': 'AI', 'text': 'You can test soil drainage by digging a hole about 30 cm (12 inches) deep, filling it with water, and observing how long it takes to drain. If it takes more than 4-6 hours, your soil has poor drainage. To improve it, you can add sand, compost, or organic matter. Would you like recommendations for tomato varieties that resist fungal diseases in humid conditions?'}, {'speaker': 'User', 'text': 'Yes! What varieties are best for humid climates?'}, {'speaker': 'AI', 'text': 'In humid environments, you should select fungal-resistant tomato varieties like Defiant PhR, Mountain Magic, or Big Beef. These tomatoes have natural resistance to blight and mildew. Additionally, planting in raised beds or mounded rows helps keep the roots drier. Would you like advice on how to manage irrigation in a humid climate?'}, {'speaker': 'User', 'text': 'Yes! Since my farm is already humid, how should I water my tomatoes efficiently?'}, {'speaker': 'AI', 'text': 'In humid climates, less frequent watering is needed to avoid waterlogging. Water only when the top 2 inches of soil feel dry, and use drip irrigation to keep leaves dry and prevent fungal infections. Overhead watering should be avoided. Have you considered using mulch to regulate moisture levels?'}, {'speaker': 'User', 'text': \"I haven't used mulch before. What type should I use in a wet climate?\"}, {'speaker': 'AI', 'text': 'Use light, well-aerated mulch such as pine needles, straw, or shredded bark to regulate moisture without trapping excessive humidity. Avoid dense mulches like fresh grass clippings, as they can encourage mold. Would you also like pruning techniques to improve airflow?'}]\n",
      "['Climate = humid', 'Focus on drainage and air circulation', 'Use fungal-resistant varieties', 'Water only when topsoil is dry', 'Use breathable mulch']\n"
     ]
    }
   ],
   "source": [
    "# Load all datapoints into a list\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    datapoints = [json.loads(line) for line in f]\n",
    "\n",
    "# Example: Access the first datapoint\n",
    "first_dp = datapoints[0]\n",
    "print(first_dp[\"dialogue_id\"])\n",
    "print(first_dp[\"original_context\"])\n",
    "print(first_dp[\"logical_shift\"][\"original_logic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete. Saved to: converted_with_system.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_path = jsonl_path\n",
    "output_path = \"converted_with_system.jsonl\"\n",
    "\n",
    "def convert_ai_to_system(data):\n",
    "    # Update speaker in original_context\n",
    "    for turn in data.get(\"original_context\", []):\n",
    "        if turn.get(\"speaker\") == \"AI\":\n",
    "            turn[\"speaker\"] = \"System\"\n",
    "    # Update speaker in correct_revised_response\n",
    "    if data.get(\"correct_revised_response\", {}).get(\"speaker\") == \"AI\":\n",
    "        data[\"correct_revised_response\"][\"speaker\"] = \"System\"\n",
    "    # Update speaker in wrong_revised_response\n",
    "    if data.get(\"wrong_revised_response\", {}).get(\"speaker\") == \"AI\":\n",
    "        data[\"wrong_revised_response\"][\"speaker\"] = \"System\"\n",
    "    return data\n",
    "\n",
    "# Load, convert, and save\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "        updated_item = convert_ai_to_system(item)\n",
    "        outfile.write(json.dumps(updated_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Conversion complete. Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teammate_json_path = \"final_dataset2.json\"      \n",
    "your_jsonl_path = \"final_data.jsonl\"            \n",
    "\n",
    "with open(teammate_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    teammate_data = json.load(f)  \n",
    "\n",
    "with open(your_jsonl_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    for entry in teammate_data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
